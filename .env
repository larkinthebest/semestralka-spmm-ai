# LLM API Keys
# Get your Gemini API key from https://aistudio.google.com/app/apikey

# Get your OpenAI API key from https://platform.openai.com/account/api-keys

# Get your OpenRouter API key from https://openrouter.ai/keys
OPENROUTER_API_KEY="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"

# Ollama Configuration (for local models)
# Set OLLAMA_BASE_URL if Ollama is running on a different host/port
OLLAMA_BASE_URL="http://localhost:11434"
# Set OLLAMA_MODEL_NAME to your preferred local model (e.g., llama3, mistral)
OLLAMA_MODEL_NAME="llama3"

# LLM Provider Order (comma-separated, lowercase)
# Providers will be tried in this order. Ollama is prioritized for local models.
LLM_PROVIDERS_ORDER="ollama,openrouter,gemini,openai"

# Other configurations
DATABASE_URL="sqlite:///./ai_tutor.db"
GEMINI_API_KEY="AIzaSyDadLwxEZ3XSI-oSRWPm5y_-0Lr_3N1NPw"
OPENAI_API_KEY="sk-efgh5678efgh5678efgh5678efgh5678efgh5678"
